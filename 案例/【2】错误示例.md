# Pattern | Claude都出4.5了，你还不懂视觉能力的边界与潜力

上周我用Claude分析一张复杂的技术架构图，它不仅读懂了微服务之间的调用关系，还给我生成了Kubernetes部署清单。我当时很惊讶，这视觉理解能力太强了。

然后我突发奇想，给它上传了一张桌面截图，让它数一下图标有多少个。Claude说"大约20个"，我数了下，23个。

我突然意识到，Claude Vision在某些场景强到惊人，在某些任务上却有明确边界。

我上网查了下，发现很多人在吐槽类似的问题：

1. Claude Vision处理PDF时，为什么有时只提取文字，有时能理解图表？
2. 用Claude数图片里的物体总是不准，这是技术限制还是我用法不对？
3. Claude Vision vs GPT-4V vs Gemini，处理技术文档和代码截图谁更强？
4. 什么时候该用Claude Vision，什么时候该用传统OCR工具？
5. Claude能把手绘UI草图转成前端代码吗？准确率怎么样？

---

## Vision能力的真实边界

我仔细研究了Claude Vision的官方文档，发现它的能力边界很清晰，可以分成三类：特别擅长、基本可用、明确不行。

### 特别擅长的场景

**技术文档理解**是Claude Vision的核心优势。比如你上传一张包含图表、表格、流程图的技术文档，Claude能理解其中的逻辑关系。Claude 3.5 Sonnet在标准视觉基准测试中超越了Claude 3 Opus，这个提升在图表解读任务上最明显。

举个例子。给Claude一张数据库架构图，它不只是识别出"MySQL""Redis"这些文字，而是理解"MySQL负责持久化存储，Redis做缓存层，中间通过连接池交互"这种结构性关系。

**代码截图识别**也非常强。我经常在Cursor里遇到报错，截图发给Claude，它能看懂错误堆栈、定位问题代码、给出修复建议。这不是简单的OCR，而是结合了代码理解能力的视觉分析。

真实的应用场景还有很多，比如UI mockup转React组件（看懂设计稿的布局和组件关系）、浏览器报错截图生成代码补丁（理解错误上下文）、架构图自动生成部署清单（理解基础设施关系）。

这些任务的共同点是：需要理解图像中的**结构化信息**和**语义关系**，而不只是识别文字。

### 明确的限制

Claude官方文档明确列出了三大限制，这不是产品缺陷，而是技术边界。

**空间推理能力有限**。比如你让Claude读一个模拟时钟，告诉你现在几点，它可能会出错。你给它一张国际象棋棋盘，让它描述"白色骑士的精确位置"，它可能说不清楚。

为什么会这样？因为Vision模型擅长理解语义（这是什么），但对精确的空间定位（在哪里、有多远、什么角度）能力较弱。学术研究显示，所有主流视觉语言模型在2D导航任务上表现都不好，Claude在网格导航上有一些成功案例，但也仅限于可以用计数启发式方法的简单场景。

**计数不精确**。就像开篇我说的，Claude可以给出近似数量，但面对大量小物体时准确率下降。研究表明，模型的错误既来自对遮挡的处理能力不足，也来自图像计数本身的困难。你让Claude数散落的螺丝钉有多少颗，它可能说"大约50个"，实际是47个。

这个限制的本质是：Vision模型是通过图像的整体特征来"估算"数量，而不是像人类那样一个一个数。对于排列整齐的物体，准确率会高一些；对于散乱或部分遮挡的物体，误差就会增大。

**图像质量敏感**也是一个需要注意的问题。低质量、旋转的、小于200像素的图片，Claude可能出现幻觉或错误。这是因为图像编码过程中会调整大小以适应模型输入，小图片信息损失更多。

另外，Claude不能识别特定人物。这是隐私设计，不是技术限制。你上传一张照片问"这是谁"，Claude会拒绝回答或只描述外观特征。

### 基本可用的场景

对于一般的图像理解任务——比如描述图片内容、提取图中文字、总结场景信息——Claude Vision完全可用，但不一定是最优选择。

如果你只需要提取图片中的文字（纯OCR任务），传统OCR工具（如Tesseract）可能更快更便宜。如果你需要理解文字背后的含义（比如读懂一张报表并分析趋势），Claude Vision的优势就体现出来了。

---

## PDF Citations的秘密武器

我之前一直很困惑，为什么同样是上传PDF，有时候Claude能看懂图表，有时候只能提取文字。后来研究文档才发现，Claude处理PDF有两种模式。

### 两种模式的巨大差异

**基础模式**就是纯文本提取。Claude把PDF当作txt文件处理，只提取文字内容，忽略图表、图片、排版。这种模式速度快、成本低，但丢失了大量信息。

**Citations模式**才是完整视觉理解。Claude同时分析文本和图像，理解图表、表格、公式。每页内容会生成页码级引用（Citations），你可以追溯到具体哪一页。

关键是：**在Converse API中，必须启用Citations才能获得完整的视觉PDF理解能力**。如果没有启用，API会自动退回到基础文本提取模式。

你可能以为Claude在"看"PDF，实际上它可能只在"读"纯文本。这不是模型能力不足，而是API配置问题。

### Citations的工作原理

当你启用Citations后，Claude会：

1. 提取每页的文本内容
2. 将页面转换成图像
3. 同时分析文本和图像，理解页面的完整语义
4. 生成每个回答对应的页码引用

这个机制在法律、学术、金融等需要精确引用的场景特别有价值。你问"合同中关于违约金的条款是什么"，Claude不仅给出答案，还告诉你"见第12页第3段"。

**模型支持**：Citations功能在Claude Opus 4、Sonnet 4、Sonnet 3.7、Sonnet 3.5v2上可用。如果你用的是Haiku或更早的模型，没有这个能力。

### 实际使用建议

如果你只需要提取PDF的文字（比如把扫描件转成txt），不用启用Citations，基础模式足够。

如果你的PDF包含大量图表、表格、公式（比如技术白皮书、研究报告、财务报表），必须启用Citations，否则Claude看不懂图表内容。

一个细节：引用页码时，使用PDF阅读器显示的页码，而不是文档内打印的页码。比如封面是第1页，即使上面印着"Page i"，Claude也会引用为"第1页"。

---

## 该选Claude还是GPT-4V？

Claude Vision、GPT-4V（GPT-4o）、Gemini 2.5 Pro都是2025年的主流视觉模型，但各有侧重。

### 编码与技术文档：Claude领先

在SWE-bench（软件工程基准测试）上，Claude 4达到72.7%准确率，显著超过GPT-4.1的54.6%和Gemini 2.5 Pro的63.8%。这个测试模拟真实编程任务，包括读懂代码、修复bug、实现功能。

这意味着什么？你上传一张技术架构图或代码截图，Claude理解得更准确，生成的代码质量更高。这不是小幅优势，而是接近20个百分点的差距。

如果你的工作场景是处理技术文档、代码review、架构图分析，Claude Vision是首选。

### 数学推理：Gemini更强

Gemini 2.5 Pro在AIME 2025数学竞赛题上达到86.7%准确率，显著超过Claude和GPT。如果你的任务涉及复杂数学公式、几何图形推理，Gemini可能更合适。

但这个优势有限定条件：Gemini不使用外部工具。如果允许工具调用，GPT-4.5的o3模型可以达到98-99%。

### 多模态集成：GPT-4o体验最好

GPT-4o原生集成文本、图像、语音，你可以直接语音对话让它分析图片。Claude Vision目前只支持文本+图像，不支持语音输入。

如果你需要流畅的多模态交互体验（比如边看图边语音讨论），GPT-4o更友好。但如果你是API开发者，这个差异影响不大。

### 上下文窗口：各有千秋

Gemini支持200万tokens上下文，可以上传整本书分析。Claude Sonnet 4支持64K输出（可以生成完整代码库），但输入上下文是20万tokens。GPT-4.1上限是32,768 tokens。

如果你需要处理超长文档，Gemini的上下文优势明显。但要注意"Lost in the Middle"问题——上下文太长，中间部分容易被忽略。

### 选择建议

- **日常技术工作**（代码、文档、架构图）：Claude Vision
- **学术研究**（海量文献、数学推理）：Gemini 2.5 Pro
- **多模态交互**（语音+图像）：GPT-4o
- **法律/金融文档**（需要精确引用）：Claude Vision + Citations

成本也是考虑因素。Claude Vision的定价在三者中居中，但如果启用Citations和Extended Thinking，成本会显著上升。Gemini最便宜，GPT-4o在高负载场景下成本较高。

---

## 快速解答

到这里这篇文章就结束了，关于开篇提到的5个问题，你应该有答案了。

为什么Claude处理PDF时表现不一致？核心原因是**Citations开关**。在Converse API中，必须启用Citations才能获得完整的视觉理解能力，否则Claude只会提取纯文本，忽略图表。如果你在Web界面上传PDF，系统会自动启用完整模式；但如果你用API，需要手动配置。这个机制在Claude Opus 4、Sonnet 4、Sonnet 3.7上可用。

至于计数不准的问题，这是**技术限制不是用法问题**。学术研究证实，所有视觉语言模型在物体计数任务上准确率都不高，尤其是面对大量小物体或部分遮挡的场景。Claude的计数是基于图像整体特征的估算，而不是逐个识别。如果你需要精确计数，应该用专门的物体检测算法（如YOLO），而不是通用Vision模型。

在技术文档和代码截图处理上，**Claude明显领先**。SWE-bench测试显示，Claude 4在软件工程任务上准确率达到72.7%，比GPT-4.1高出18个百分点。这个优势在图表理解、代码分析、架构图解读任务上最明显。如果你的工作场景是这些，Claude Vision是首选。Gemini在数学推理上更强，GPT-4o在多模态交互上体验最好，但处理技术内容不如Claude。

什么时候该用Claude Vision，什么时候该用传统OCR？判断标准是**你需要理解还是只需要识别**。如果只是提取图片中的文字（比如把扫描件转成txt），传统OCR工具（Tesseract）更快更便宜。如果需要理解文字背后的含义——比如读懂一张报表并分析趋势、理解架构图的服务关系——Claude Vision的优势就体现出来了。

最后，Claude确实可以把UI草图转成前端代码，这是官方文档列出的真实应用场景之一。准确率取决于草图的清晰度和复杂度。如果是简单的线框图（wireframe），Claude能生成基本可用的React组件；如果是复杂的交互流程，可能需要你补充说明。不过，生成的代码通常需要你进一步调整，不能直接投入生产。

---

## 深入交流

想要深入交流AI实践经验？欢迎关注，一起探讨AI时代的无限可能！

---

> ### 关于本人 ｜ 黄彦湘
> 深耕互联网行业9年，专注前端开发技术方向，现为广州执业律师，同时兼备专利代理师资质。基于丰富的技术背景和法律实践经验，现为深度实践（Deepractice）社区核心贡献者，致力于推动AI深度实践在法律、小说创作等多元领域的创新应用与探索。
> **全网同名**：明易AI实践

---
