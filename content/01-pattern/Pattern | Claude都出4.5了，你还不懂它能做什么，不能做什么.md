# Pattern | Claude都出4.5了，你还不懂它能做什么，不能做什么

很多人对Claude的认知，还停留在“能写代码”、“能分析图片”这类模糊的印象上。这种不精确的理解常常导致两个极端：要么过分高估，让它处理超出能力范围的任务后大失所望；要么大材小用，只用它写写文案，白白浪费了其深层潜力。

Claude的设计哲学——宪法AI、HHH原则、场景化模型家族——固然重要，但对于使用者而言，最关键的问题是：它到底能做什么？边界又在哪里？

这篇文章将为你清晰地划出Claude的能力边界。

## 不只是“写字”：生成、推理与解决问题

Claude最基础的能力是文本生成，但这四个字远不能概括其全部。它的强大之处在于**将理解、推理和生成融为一体**，这与一些模型单纯追求“生成流畅文本”的核心目标有所不同。Claude的核心是“遵守原则，解决问题”。

这种能力体现在多个方面。在内容创作上，它能驾驭文章、博客、营销文案等多种形式。在对话交互中，得益于HHH（Helpful, Honest, Harmless）原则和记忆工具（Memory Tool），它能构建出色的客服机器人和虚拟助手，不仅能理解上下文，还能保持稳定的角色。

它更是一个强大的数据与文本处理器，擅长分类、总结、翻译和格式转换。其中，它的引用（Citation）机制尤为出色，能精确地告诉你答案源自某份PDF的第几页，而非模糊的猜测。在代码和技术工作中，最新版的Sonnet 4.5之所以能在软件工程基准测试（SWE-bench）上取得高分，并非因为它写的代码更多，而是因为它能连续工作、并行调用工具，并深刻理解大型代码库的复杂结构。

对于更复杂的分析任务，如"在一份200页的法律文件中找出所有潜在风险"，Opus 4.1的细节追踪能力便能派上用场。这一切的背后，是System Prompt与宪法AI的结合，让Claude在扮演特定角色或保持某种语气时，不会像某些模型一样聊着聊着就"人设崩塌"。同时，它的"诚实"原则也让它在教育场景中更值得信赖——当不确定时，它会坦诚地承认"我不知道"，而不是编造一个看似合理的答案。

---

上面说的是Claude的"基本功"——文本理解和生成。但这还不是全部。

接下来，我们要聊的是那些**让Claude从"能聊天"跃升为"能干活"的关键能力**：能不能看图？能不能深度思考？能不能调用外部工具？能不能真正写生产级代码？

这些问题的答案，决定了Claude到底是"聊天机器人"还是"生产力工具"。

## Vision：能看，但有"盲区"

很多模型都说自己"支持视觉"，但**能看**和**看得准**是两回事。

从Claude 3开始，模型具备了视觉（Vision）能力，可以分析图表、处理PDF、从图片中提取信息。这意味着什么？

**没有视觉能力的模型**：你给它发一张销售数据图，它只能回复"抱歉，我看不到图片"。
**有视觉能力的Claude**：它能告诉你"这是柱状图，显示Q2销售额比Q1增长了32%，最高点在5月"。

这个差距，直接决定了AI能不能处理真实世界的工作场景——因为现实中，文档里有图、报告里有表、合同里有扫描件。

Claude能够识别图表类型、判断数据趋势、描述物体间的相对位置（例如"杯子在桌子上"），也能从图片中提取文字。处理PDF时，其页码级引用功能非常实用——它能告诉你"答案在第23页第二段"，而不是模糊地说"文档里提到过"。

但是——这扇窗户望出去的世界并非完美无瑕。

它的视觉能力存在根本性限制。首先，**它无法识别特定人物**。这是一个基于隐私和合规的政策限制，而非技术瓶颈。你无法用它来辨认照片中的人物身份。其次，**它的空间推理能力有限**。虽然能描述相对位置，但无法进行精确的距离测量或复杂的几何推理。让它读取模拟时钟的时间，或者说出棋盘上棋子的精确坐标，结果很可能出错。同样，**它在精确计数上也存在困难**，尤其是当图片中包含大量微小物体时，计数结果往往只是一个估算。最后，**不要指望它能准确鉴别AI生成的图片**，它同样会猜错。

为什么会这样？根源在于其工作原理："图像编码→文本理解"。

通俗地说：Claude看图的方式，就像你把一张照片压缩成1600个字的描述，然后凭这段描述去理解图片。这个过程中，**精确的空间位置、小物体的细节、人脸特征**都会在压缩时被损耗掉。

这就好比让一个人看完一张图后闭上眼睛，凭记忆回答"图里有几只鸟"——大概数量能说对，但精确数字？很难。

这不是Claude的问题，而是当前所有视觉模型共同面临的技术挑战。

## Extended Thinking：给模型一点"思考时间"

你有没有遇到过这种情况：问AI一个数学题，它"秒回"一个错误答案？

这是因为**大部分模型是"边想边说"**——它们接收到问题后，立刻开始输出，没有"打草稿"的过程。就像考试时不列草稿纸，直接在答题卡上写答案，错了也来不及改。

Sonnet 4.5引入的"扩展思考"（Extended Thinking）功能，改变了这一点。

它允许Claude在给出答案前，先在一个"草稿本"（Thinking Block）里推演：逐步分析问题、列举可能性、排除错误选项，最后再给你最终答案。

**没有Extended Thinking的模型**：
```
问题：3x + 5 = 14，x等于多少？
回答：x = 3！（错了，它算快了）
```

**有Extended Thinking的Claude**：
```
问题：3x + 5 = 14，x等于多少？
[内部思考]：
- 先移项：3x = 14 - 5 = 9
- 再除以3：x = 9 / 3 = 3
- 验证：3×3 + 5 = 14 ✓
回答：x = 3
```

这并非玄学，其背后是名为"串行测试时计算"（Serial Test-time Compute）的硬核技术。

这样做的好处是显而易见的。Anthropic的数据表明，**数学问题的准确率会随着思考Tokens的对数而增长**。换言之，让Claude“多想一会儿”，尤其是在处理数学证明、逻辑推理、代码调试这类需要多步推理的复杂问题时，准确率会得到显著提升。

当然，这种能力也有代价。首先，Extended Thinking追求的是确定性的推理过程，因此**不能与控制“随机性”的temperature参数同时使用**。其次，思考也是有成本的，“思考Tokens”需要额外付费。如果你让Claude深度思考一个复杂问题，由此产生的数千个思考Tokens将是一笔不小的开销。

## Tool Use：能力的边界，由工具定义

一个再聪明的大脑，如果没有手脚，也干不了什么实事。

Claude本身是一个语言模型——它会"想"，但不会"做"。它能告诉你"应该把这个文件重命名为report_final.pdf"，但它自己改不了文件名。它能分析出"这段代码有bug"，但它不能直接打开你的编辑器帮你修复。

这就是为什么Anthropic提供了9个"服务器工具"（Server Tools）——**这些工具就是Claude的"手脚"**，让它从"纸上谈兵"变成"真能干活"。

这些工具赋予了Claude一系列"超能力"：
* **Computer Use**：像人一样操作电脑桌面，控制鼠标键盘，实现跨应用的自动化。
* **Memory Tool**：实现跨对话记忆，将关键信息持久化保存，解决了上下文窗口的局限。
* **Web Search & Fetch**：官方实现的检索增强生成（RAG），让Claude可以搜索和抓取网页内容。
* **Code Execution & Bash**：在安全的沙盒环境中执行Python代码和Bash命令。
* 以及PDF处理、文本编辑等实用工具。

**没有工具的AI**：
```
你：帮我查一下最新的Python 3.12有哪些新特性
AI：抱歉，我的知识截止到2024年1月，无法获取最新信息
```

**有工具的Claude**：
```
你：帮我查一下最新的Python 3.12有哪些新特性
Claude：[调用Web Search] → 找到官方文档 → [调用Web Fetch] → 提取关键信息
Claude：Python 3.12主要新特性包括：1) 更灵活的f-string语法...
```

这里的核心思想是：**工具定义了能力的边界**。

Claude本身不会"上网"或"操作电脑"，但它能调用相应的工具来实现这些功能。这也意味着，**如果没有现成的工具，某些任务就无法完成**。比如，你无法让Claude直接"发微信"，因为Anthropic没有提供对应的工具（除非你自行开发）。

## SWE-bench高分背后：真实世界开发能力的试金石

Sonnet 4.5在SWE-bench Verified测试集上获得业界最高分——这意味着什么？

先说说什么是SWE-bench。很多AI测试都是"写个冒泡排序"、"实现一个二分查找"这种教科书式的编程题。但SWE-bench完全不同：

**传统编程测试**：
```
题目：请实现一个函数，判断一个数是否为质数
环境：空白编辑器
评分：代码能跑就行
```

**SWE-bench测试**：
```
题目：修复Django项目的Issue #45732（真实bug）
环境：30万行代码的真实项目
要求：
  - 读懂30万行代码库
  - 定位bug在哪个文件哪一行
  - 理解项目的架构和规范
  - 写出符合代码风格的修复
  - 通过所有单元测试
```

这就是为什么SWE-bench被称为"真实世界开发能力的试金石"——它测试的是AI能否像程序员一样工作。

"Verified"子集更是筛选出了其中定义明确、可被自动验证的高质量任务。因此，Sonnet 4.5的高分意味着它具备了：
- 理解复杂代码库（几十万行代码）
- 定位问题根源（在茫茫代码中找bug）
- 编写生产级修复代码（不是玩具代码，是真能用的）

这标志着AI在辅助软件工程方面迈出了一大步。

但我们也要认识到它的局限性。SWE-bench主要测试“修复Bug”的能力，而不涉及“系统架构设计”、“文档撰写”或“代码审查”（Code Review）。所以，这个高分证明了它是一个强大的开发助手，但并不意味着它能完全替代程序员。

## 无法回避的限制：它不是万能的

在赞叹其能力的同时，我们必须清醒地认识到Claude无法做到的事情。

首先是**幻觉问题**。所有大语言模型都无法完全避免编造看似合理但实则错误的信息。Claude的宪法AI训练虽然能凭借其“诚实”原则减少幻觉，但无法根除。因此，在医疗诊断、法律意见、金融决策等要求100%准确的严肃场景中，绝对不能依赖它的判断。

其次，**200K的上下文窗口并不等同于200K的理解力**。它更像是“工作记忆”而非“长期知识”。向模型输入一份超长文档，它能将其“载入内存”，但随着上下文长度增加，模型的“注意力”会被稀释，对细节的理解和记忆质量会下降。

最后，**Claude无法实现完全自主**。Sonnet 4.5虽然能“连续工作30小时”，但这必须在人类设定的明确任务、边界和工具权限内进行。它能自主执行“修复这个代码库的所有类型错误”，但不能“自己决定下一步该做什么”。尤其在使用Computer Use这类高权限工具时，Anthropic强烈建议在沙盒中运行，并对关键操作设置人工确认环节，因为AI犯错的风险太高。

## 总结：如何真正用好Claude？

现在，我们可以对Claude的能力边界做一个总结了。它的边界并非简单的“能”或“不能”，而是一个关于“在什么场景、用什么方式、能做到什么程度”的复杂问题。

* **文本与代码**：能生成高质量内容和代码，但不能保证100%准确，需要人类监督和验证。
* **视觉分析**：能理解图片和PDF，但无法识别人脸、进行精确的空间推理或完美计数。
* **复杂推理**：能通过“扩展思考”提升准确率，但这需要付出额外的经济成本。
* **外部能力**：能通过调用工具扩展能力，但其边界完全由可用工具定义。
* **自主工作**：能在明确指令下长时间自主执行任务，但绝不能脱离人类的监督和控制。

理解这些边界，你才能摆脱对AI的盲目崇拜或无端失望。关键不在于问“Claude能做什么”，而在于思考“在何种条件下，我能用它来完成什么”。

---

## 深入交流

想要深入交流AI实践经验？添加微信，一起探讨AI时代的无限可能！

![微信二维码](../assets/二维码.jpg)

> ### 关于本人 ｜ 黄彦湘
> 深耕互联网行业9年，专注前端开发技术方向，现为广州执业律师，同时兼备专利代理师资质。基于丰富的技术背景和法律实践经验，现为深度实践（Deepractice）社区核心贡献者，致力于推动AI深度实践在法律、小说创作等多元领域的创新应用与探索。
>
> **全网同名**：明易AI实践

> ### 关于深度实践
> Deepractice 深度实践 致力于成为AI时代的标准制定者，基于开源生态，为AI应用提供标准化基础设施。
> * 📧 **联系我们**：sean@deepracticex.com
> * 🌐 **官网**：deepractice.ai
> * 💻 **GitHub**：[https://github.com/Deepractice](https://github.com/Deepractice)
