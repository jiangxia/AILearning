# Pattern | Claude都出4.5了，你还不懂——为什么这么贵，怎么省钱

最近，Reddit 上关于 Claude 的吐槽火了。一位 Pro 用户抱怨每月 20 美元却只能发 50 次消息，平均每条消息 0.4 美元，“比打车还贵”。更有一位开发者，因为 AI 意外地重复读取文件，一小时内就被消耗了 100 美元的 API 费用。

这些经历汇成了许多用户的共同感受：Claude 很好用，但也真的贵。

## 为什么这么贵

Claude按Token计费。Token是啥？翻译一下，就是文本的计量单位。750个英文单词大概1000 tokens，一个汉字约1.5-2个tokens。

关键来了：**输出tokens比输入贵5倍**。

Sonnet 4.5举例：
- 输入：3美元/百万tokens
- 输出：15美元/百万tokens

什么意思？你让Claude写篇2000字文章，提示词可能只有100字（200 tokens），但Claude输出的2000字相当于3000-4000 tokens。成本主要来自输出，不是你的提问。

所以"让Claude多写一点"特别贵。

### Extended Thinking：思考也要钱

Sonnet 4.5的扩展思考功能确实强——回答前推演、验证，准确率显著提高。

但"思考过程"也产生tokens。

Anthropic自己的数据：数学问题准确率随思考tokens对数增长。说白了，让Claude"多想一会儿"，就得为"思考tokens"买单。一个复杂数学证明，可能产生几千个思考tokens。

### 上下文窗口：200K是双刃剑

Claude的200K上下文窗口能装一本500页的书。听起来厉害，但问题是：**输入的每个字都要计费**。

上传一份100页PDF（约75K tokens），即使只问个简单问题，这75K的输入成本跑不掉。更糟的是，接着追问第二个问题，这75K会再次计入上下文...再收一次费。

很多人抱怨"tokens不知不觉就没了"，根源就在这。

### 工具调用：每次调用都烧钱

Claude调用网页搜索、代码执行、文件读取，每次都产生额外tokens。

前面那个开发者一小时烧掉100美元，就是AI不断重复调用文件读取工具。每次读取，文件内容被重新载入上下文，tokens翻倍累加。

## 一笔账算清实际开销

了解了成本构成后，我们来通过几个真实场景，计算一下具体花费。

**场景一：日常写代码**
假设你每天让 Claude 写 10 个函数，每个函数的提示词约 500 tokens，生成的代码为 1000 tokens。
使用 Sonnet 4.5 API 的每日成本约为 0.165 美元，**每月合计约 5 美元**。在这种高频、低量的场景下，API 远比 Pro 订阅划算。

**场景二：分析长文档**
假设你每天需要处理 3 份 70 页左右的文档（约 50K tokens），并就每份文档提问和获取分析（约 2200 tokens）。
每日成本约为 0.54 美元，**每月合计约 16 美元**。这个价格接近 Pro 订阅，但好处是完全没有使用次数的限制。

**场景三：内容创作**
假设你每天写 5 篇 3000 字的文章，每篇的提示词为 300 tokens，生成内容约 4500 tokens。
每日成本约为 0.34 美元，**每月合计约 10 美元**。API 依然是更经济的选择。

将场景三与 DeepSeek 对比，结果更为残酷。使用 DeepSeek V3.2-Exp 完成同样的工作，每月的成本仅为 **0.3 美元**。Claude 10 美元，DeepSeek 0.3 美元，这正是那 35 倍价差的直观体现。

## 怎么省钱

**定期清空对话**

Claude对话是持续的，每次提问都带上之前所有记录。对话越长，输入成本越高。

我的做法：完成任务立刻`/clear`清空。需要保留关键信息时，用`/compact`生成摘要，然后拿摘要开新对话。

实测：长对话及时清空，省70-80%输入成本。

**选对模型**

简单任务用Haiku（0.80美元/4美元）——文本转换、语法检查。写代码、分析文档用Sonnet（3美元/15美元）。大型代码库重构、深度研究才用Opus（15美元/75美元）。

Haiku转JSON到YAML花0.01美元，Sonnet要0.05美元。成本差5倍，效果一样。

**Prompt缓存**

反复用的内容缓存起来，下次只收原价10%。项目规范、固定指令集都能缓存。

Anthropic数据：批量任务配Prompt缓存，成本降**95%**。原来100块，现在5块。

**减少输入**

精简提示词："我希望你能帮我分析这份客户反馈报告"改成"分析报告，提取问题点，按严重度排序"。30 tokens压到12 tokens。

拆大文件：5000行文件拆成10个500行小文件，Claude每次只读1-2个相关文件。输入tokens从5000降到1000，省80%。

在`CLAUDE.md`里明确告诉Claude忽略`node_modules`、`build`。

**控制输出+监控成本**

输出比输入贵5倍。直接说："用JSON格式，不超过200字"或"只给结论，不要过程"。

2000 tokens详细分析花0.03美元，300 tokens核心总结花0.0045美元。成本差6倍。

定期用`/cost`命令查看消耗。知道花了多少，才能判断该不该清空对话，该不该换便宜模型。

## 写在最后

毫无疑问，Claude 是一款昂贵的工具。无论是 API 价格还是高阶订阅，都设立了不低的门槛。

但这份昂贵，对应的是其在 AI 安全、长上下文处理和复杂推理能力上的持续投入。对于重度用户而言，与其抱怨价格，不如掌握方法。通过精细化地管理输入、输出，并做出合理的模型选择，完全可以将 API 成本控制在每月 10 美元以内，获得远超 Pro 订阅的灵活体验。

最可怕的，永远是稀里糊涂地使用，然后莫名其妙地烧钱。只有搞清楚 Claude 的成本结构，并掌握这些省钱策略，你才能真正驾驭这个强大的工具，让每一分钱都物有所值。

---

## 深入交流

想要深入交流AI实践经验？添加微信，一起探讨AI时代的无限可能！

![微信二维码](../assets/二维码.jpg)

> # 关于本人 ｜ 黄彦湘
> 深耕互联网行业9年，专注前端开发技术方向，现为广州执业律师，同时兼备专利代理师资质。基于丰富的技术背景和法律实践经验，现为深度实践（Deepractice）社区核心贡献者，致力于推动AI深度实践在法律、小说创作等多元领域的创新应用与探索。
> **全网同名**：明易AI实践
