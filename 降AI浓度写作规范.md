# 降AI浓度写作规范

> **目标**：AI浓度从100% → <30%（朱雀检测标准）

---

## 📐 基础风格（铁律）

**非法律类文章必须遵循阮一峰博客风格**

**核心特征**：
- 亲切但专业，深入浅出
- 多用"我们"、"你"建立对话感
- 技术原理必配通俗理解
- 句号为主，简洁明快
- 段落叙述为主，避免过度分点
- 几乎不用emoji（最多章节标题用符号类）

**验证方法**：写完问自己"这篇文章看起来像阮一峰写的吗？"如果不是，必须重写。

**详细定义**：参见 `workflow.md` 第417-474行

---

## 🎯 朱雀验证的成功法则

基于Tool Use文章的低AIGC值内容（48-50%）提炼：

### 1. 具体化替代抽象化
❌ "MCP提供了标准化的能力声明机制"
✅ "10个服务、10种语言，只需要20个实现，而不是100个"

**规律**：用数字、路径、命令替代概念描述

### 2. 类比法降低认知成本
每个新概念找一个熟悉的事物类比：
- USB-C接口（解释MCP标准化）
- LSP协议（解释协议设计）
- 程序员调试（解释反馈循环）

**规律**：新事物必须跟旧事物对比

### 3. 对比法建立认知锚点
- LangChain vs MCP
- Plugin模式 vs MCP模式
- N×M vs N+M

**规律**：对比才能快速理解差异

### 4. "说人话"强制翻译
技术描述后必须跟一句"说人话就是"

❌ "Claude基于能力声明进行自主决策"
✅ "说人话就是：Claude看到声明，自己决定什么时候用"

### 5. 问题驱动而非知识灌输
从读者疑问出发：
- 为什么连不上？→ 工具命名规范
- 14.9%准确率有啥用？→ 辅助人类不是替代

**规律**：从疑问出发，而非知识体系出发

### 6. 实战细节建立可信度
给出可执行的细节：
- 日志路径：`~/.claude/logs/mcp.log`
- 调试命令：`claude --debug`
- JSON schema示例

**规律**：可执行细节 > 原理性描述

### 7. 逻辑链条短而直接
用箭头连接步骤，强制精简：
收集上下文→执行动作→验证结果→重复

**规律**：4步以内，每步都是动词

---

## 🔍 AI特征识别与改写

### 【特征1】对称性过强
**症状**：前者/后者、一方面/另一方面、既...又...

❌ API返回的response里，会有独立的"thinking"块和"text"块，前者是思考过程，后者是最终答案

✅ 内部思考空间会返回两个内容，一个是思考过程，一个是最终答案

**改法**：用"一个是...一个是..."替代对称结构

---

### 【特征2】抽象性过高
**症状**：技术概念没有生活化比喻

❌ 扩展思考给了Claude一个"内部思考空间"——最多可以用64,000个thinking tokens来推理

✅ 在扩展思考之前，Claude是说话不打草稿的，你问他问题，他直接丢答案。有了扩展思考就不一样了，Claude会先在"草稿纸"上写推理过程。

**改法**：每个技术概念后必须跟生活化比喻（草稿纸、老中医、看病）

---

### 【特征3】书面化过渡
**症状**：此外、另外、值得注意的是

❌ 此外，扩展思考还支持一个强大功能：交错思维

✅ 你可能要问了，DeepSeek R1不是也可以做到麽？Claude的扩展思考跟DeepSeek有什么区别？这个问题问到核心了，本质的问题是交错思维。

**改法**：用疑问句或口语表达过渡

---

### 【特征4】观点堆砌
**症状**：一段讲多个观点，段落超过5句话

❌ 扩展思考不是免费午餐。平均延迟156秒，也就是说你问一个问题，要等将近2分半。更要命的是成本——thinking过程会生成大量tokens（通常是正常输出的3-5倍），一次64K的深度推理就要花掉约$0.96，一天调用100次就烧掉$96。

✅ 当然，有一利就有一弊，扩展思考的问题也很突出：又贵又慢。一个问题平均延迟两分半钟，而且还消耗大量tokens。

所以拓展思考好不好，关键是用对地方。类似软件架构设计这种对结果要求极高的决策，多花时间跟钱是可以接受的。

**改法**：一段只讲一个观点，每段不超过3句话

---

### 【特征5】流程罗列
**症状**：只有步骤A→B→C，缺乏完整故事

❌ 比如分析线上事故，它会"调日志→思考→调监控→再思考→调SQL分析→定位根因"

✅ 交错思维模式就像经验丰富的老中医，他不会那么"死板"。中医讲究望闻问切，上来先看看舌苔，发现舌苔有异常，先让患者做简单的检查，比如抽血，根据抽血的结果，如果能判断问题，就开药，否则，就让患者做进一步的检查，比如CT，最后根据所有信息去确诊。

**改法**：场景必须有起点→过程→终点，像讲故事一样完整

---

### 【特征6】功能开场
**症状**：第一段直接介绍功能特性

❌ 扩展思考给了Claude一个"内部思考空间"——最多可以用64,000个thinking tokens来推理

✅ 在扩展思考之前，Claude是说话不打草稿的，你问他问题，他直接丢答案，你还信以为真，等到后面发现有问题，已经积重难返了。

**改法**：第一段先讲用户痛点，再引出解决方案

---

### 【特征7】物化指代
**症状**：用"它"指代AI，用"能够"而非"会"

❌ 它会系统性地分析瓶颈、评估架构模式

✅ 他会系统性地分析瓶颈、评估架构模式

**改法**："它"→"他"，"能够"→"会"

---

### 【特征8】英式数字
**症状**：使用逗号分隔的英文数字格式

❌ 64,000个thinking tokens

✅ 6.4万个thinking token

**改法**：用中文习惯表达数字，去掉复数

---

### 【特征9】细节堆砌
**症状**：罗列大量技术参数和配置步骤

❌ 至于thinking budget设多少？官方建议从1024起步，逐步增加到16000。特别复杂的任务可以给到64000...

✅ （删除，非核心内容）

**改法**：删除非核心的技术参数，只保留核心逻辑

---

### 【特征10】平铺直叙
**症状**：段落间缺乏引导，没有悬念

❌ （直接把所有内容讲完）

✅ 我们后文会详细介绍。

**改法**：章节末尾设置悬念，用疑问句吸引继续阅读

---

### 【特征11】长句过多
**症状**：一句话超过2个逗号

❌ 好在Anthropic团队也注意到了这个问题，他们推出的扩展思考（Extended Thinking），就是为了让Claude像人类一样，有步骤地进行深度推理，并把完整的思考过程记录下来。

✅ 好在Anthropic团队也注意到了这个问题。他们推出了扩展思考（Extended Thinking）。这个功能让Claude像人类一样，有步骤地进行深度推理，并把完整的思考过程记录下来。

**改法**：长句拆成2-3个短句，句子不超过2个逗号

---

## ✅ 快速自检清单

写完文章后，问自己5个问题：

1. **有没有用数字/路径/命令替代抽象概念？**
   （具体化检查）

2. **有没有给新概念找类比？**
   （类比法检查）

3. **有没有跟旧事物对比？**
   （对比法检查）

4. **技术描述后有没有"说人话"翻译？**
   （翻译检查）

5. **有没有给出可执行的细节？**
   （实战细节检查）

**如果5个问题有3个以上是"否"，这段内容AIGC值必然>80%**

---

## 🔄 持续优化

发现新的AI特征时，按此格式补充：

```markdown
### 【特征X】特征名
**症状**：具体表现

❌ 原文示例

✅ 改写后

**改法**：改写方法
```

---

## 📝 版本记录

- **v1.3** (2025-10-04)：奥卡姆剃刀优化 + 融入朱雀验证的成功法则
  - 从643行压缩到约300行
  - 合并"特征+原则+示例"为一体（症状→疗法→案例）
  - 删除执行步骤（1-2-3啰嗦步骤）
  - 新增"朱雀验证的成功法则"（7条）
  - 新增"快速自检清单"（5个问题）
  - 保留阮一峰风格作为基础铁律

- **v1.2** (2025-10-04)：新增"阮一峰博客风格"基础规范

- **v1.1** (2025-10-04)：新增"长句拆短"特征

- **v1.0** (2025-10-04)：首次创建
