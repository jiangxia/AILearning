# 降AI浓度写作规范

> **使用场景**：AI写完初稿后，根据此规范识别问题并改写
>
> **核心目标**：AI浓度从100% → <30%（朱雀检测标准）
>
> **框架特点**：简单 · 可行 · 可扩展

---

## 📖 使用说明

### 三步执行流程

```
步骤1：对照"AI特征库"，识别文章中的AI痕迹
         ↓
步骤2：查找对应的"改写原则"
         ↓
步骤3：参考"示例库"中的类似案例，应用改写
```

### 快速检查清单

写完文章后，逐条检查：
- [ ] 是否有"前者/后者"等对称结构？ → 【特征1】
- [ ] 技术概念是否缺乏生活化比喻？ → 【特征2】
- [ ] 是否用"此外"、"另外"等书面过渡词？ → 【特征3】
- [ ] 段落是否堆砌多个观点？ → 【特征4】
- [ ] 场景描述是否只有流程罗列？ → 【特征5】
- [ ] 开篇是否直接介绍功能？ → 【特征6】
- [ ] 是否用"它"而非"他"指代AI？ → 【特征7】
- [ ] 数字表达是否用英文格式？ → 【特征8】
- [ ] 是否堆砌技术参数和配置细节？ → 【特征9】
- [ ] 段落间是否缺乏引导和悬念？ → 【特征10】

---

## 🔍 AI特征库（症状识别）

### 【特征1】对称性过强
**症状表现**：
- 使用"前者...后者..."
- 使用"一方面...另一方面..."
- 使用"既...又..."的平行结构

**典型案例**：
```
❌ API返回的response里，会有独立的"thinking"块和"text"块，
   前者是思考过程，后者是最终答案
```

---

### 【特征2】抽象性过高
**症状表现**：
- 技术概念没有生活化比喻
- 纯粹的术语堆砌
- 缺乏具体场景类比

**典型案例**：
```
❌ 扩展思考给了Claude一个"内部思考空间"——
   最多可以用64,000个thinking tokens来推理
```

---

### 【特征3】书面化过渡
**症状表现**：
- 使用"此外"、"另外"、"同时"
- 使用"值得注意的是"、"需要指出的是"
- 缺乏口语化的自然过渡

**典型案例**：
```
❌ 此外，扩展思考还支持一个强大功能：交错思维
```

---

### 【特征4】观点堆砌
**症状表现**：
- 一段讲多个观点
- 段落超过5句话
- 逻辑跳跃，缺乏呼吸感

**典型案例**：
```
❌ 扩展思考不是免费午餐。平均延迟156秒，也就是说你问一个问题，要等将近2分半。
   更要命的是成本——thinking过程会生成大量tokens（通常是正常输出的3-5倍），
   一次64K的深度推理就要花掉约$0.96，一天调用100次就烧掉$96。
```

---

### 【特征5】流程罗列
**症状表现**：
- 只有步骤A→B→C，没有完整故事
- 缺乏场景的起点、过程、终点
- 抽象的流程描述

**典型案例**：
```
❌ 分析线上事故时，它会"调日志→思考→调监控→再思考→调SQL分析→定位根因"
```

---

### 【特征6】功能开场
**症状表现**：
- 第一段直接介绍功能特性
- 缺乏用户痛点描述
- 没有情感共鸣的引入

**典型案例**：
```
❌ 扩展思考给了Claude一个"内部思考空间"——
   最多可以用64,000个thinking tokens来推理，然后才给出最终答案
```

---

### 【特征7】物化指代
**症状表现**：
- 用"它"指代AI
- 用"能够"而非"会"、"可以"
- 缺乏人格化表达

**典型案例**：
```
❌ 它会系统性地分析瓶颈、评估架构模式
```

---

### 【特征8】英式数字
**症状表现**：
- 使用逗号分隔的英文数字格式
- 保留英文专业术语单位
- 不符合中文表达习惯

**典型案例**：
```
❌ 64,000个thinking tokens
```

---

### 【特征9】细节堆砌
**症状表现**：
- 罗列大量技术参数
- 配置步骤过于详细
- 非核心信息占据大量篇幅

**典型案例**：
```
❌ 至于thinking budget设多少？官方建议从1024起步，逐步增加到16000。
   特别复杂的任务可以给到64000，但记住budget是上限不是目标...
   如果你用Cursor，它把thinking budget包装成了四个层级：
   think（优化代码片段）、think hard（重构模块）...
```

---

### 【特征10】平铺直叙
**症状表现**：
- 段落间缺乏引导
- 没有设置悬念
- 读者缺乏继续阅读的动力

**典型案例**：
```
❌ （直接把所有内容在当前章节全部讲完，没有"后文详述"等引导）
```

---

## ⚙️ 改写原则（对应疗法）

### 【原则1】去对称化法
**针对特征**：【特征1】对称性过强

**改写方法**：
- "前者/后者" → "一个是...一个是..."
- "一方面/另一方面" → 拆分为两段分别讲
- 避免工整的平行结构

**执行步骤**：
1. 识别对称句式
2. 改为自然随意的表达
3. 必要时拆分为多段

---

### 【原则2】场景化法
**针对特征**：【特征2】抽象性过高

**改写方法**：
- 每个技术概念后必须跟生活化比喻
- 用日常场景类比专业术语
- "草稿纸"、"老中医"、"看病"等生活化表达

**执行步骤**：
1. 识别技术术语
2. 思考对应的生活场景
3. 用"就像..."引入类比

---

### 【原则3】口语化过渡法
**针对特征**：【特征3】书面化过渡

**改写方法**：
- "此外" → "你可能要问了"
- "另外" → "举个例子就好理解了"
- "值得注意" → "这个问题问到核心了"

**执行步骤**：
1. 识别书面过渡词
2. 改为疑问句或口语表达
3. 增加互动感

---

### 【原则4】单点段落法
**针对特征**：【特征4】观点堆砌

**改写方法**：
- 一段只讲一个观点
- 每段不超过3句话
- 观点间用空行分隔

**执行步骤**：
1. 识别多观点段落
2. 拆分为多个小段
3. 每段独立成篇

---

### 【原则5】完整场景法
**针对特征**：【特征5】流程罗列

**改写方法**：
- 场景必须有：起点 → 过程 → 终点
- 像讲故事一样完整
- 添加场景细节和情境描述

**执行步骤**：
1. 识别流程罗列
2. 构建完整场景故事
3. 补充起承转合

---

### 【原则6】痛点开场法
**针对特征**：【特征6】功能开场

**改写方法**：
- 第一段先讲用户困扰/痛点
- 再引出解决方案
- 建立情感共鸣

**执行步骤**：
1. 识别功能介绍开篇
2. 思考用户痛点
3. 用痛点替换开场

---

### 【原则7】人称化法
**针对特征**：【特征7】物化指代

**改写方法**：
- "它" → "他"
- "能够" → "会"、"可以"
- 赋予AI人格化特征

**执行步骤**：
1. 全文搜索"它"
2. 替换为"他"
3. 调整动词表达

---

### 【原则8】中式数字法
**针对特征**：【特征8】英式数字

**改写方法**：
- "64,000" → "6.4万"
- "tokens" → "token"（不加复数）
- 符合中文表达习惯

**执行步骤**：
1. 识别英文数字格式
2. 转换为中文习惯
3. 简化单位表达

---

### 【原则9】精简细节法
**针对特征**：【特征9】细节堆砌

**改写方法**：
- 删除非核心的技术参数
- 删除详细的配置步骤
- 只保留核心逻辑

**执行步骤**：
1. 识别技术细节段落
2. 判断是否核心必要
3. 非核心内容直接删除

---

### 【原则10】悬念引导法
**针对特征**：【特征10】平铺直叙

**改写方法**：
- 章节末尾设置悬念
- 使用"后文会详细介绍"等引导
- 用疑问句吸引继续阅读

**执行步骤**：
1. 检查段落间连接
2. 添加引导性疑问
3. 制造阅读期待

---

## 📚 示例库（实战案例）

### 示例1：去对称化 + 场景化

**原文（特征1+2）**：
```
API返回的response里，会有独立的"thinking"块和"text"块，
前者是思考过程，后者是最终答案
```

**改写后（原则1+2）**：
```
内部思考空间会返回两个内容，一个是思考过程，一个是最终答案
```

**改写要点**：
- ✅ 去掉"前者/后者"对称结构
- ✅ 用"一个是...一个是..."自然表达

---

### 示例2：痛点开场 + 场景化

**原文（特征6+2）**：
```
扩展思考给了Claude一个"内部思考空间"——
最多可以用64,000个thinking tokens来推理，然后才给出最终答案
```

**改写后（原则6+2）**：
```
在扩展思考之前，Claude是说话不打草稿的，你问他问题，他直接丢答案，
你还信以为真，等到后面发现有问题，已经积重难返了。

有了扩展思考就不一样了。当你问问他，Claude会先在"草稿纸"上写推理过程，
此时你就可以在界面上看到他一步步得出答案的推理过程。
```

**改写要点**：
- ✅ 痛点开场（说话不打草稿、积重难返）
- ✅ 生活化比喻（草稿纸）
- ✅ 删除技术细节（64,000 tokens）
- ✅ 口语化表达（你问问他、就不一样了）

---

### 示例3：完整场景 + 单点段落

**原文（特征5+4）**：
```
比如分析线上事故，它会"调日志→思考→调监控→再思考→调SQL分析→定位根因"，
这种"工具→思考→工具→思考"的循环，远比一次性思考或盲目调用工具要高效。
```

**改写后（原则5+4）**：
```
传统模式就像医生看病，要么是让患者做全部的检查项目，然后再开药；
要么是上来看一眼症状，直接开药。

交错思维模式就像经验丰富的老中医，他不会那么"死板"。
中医讲究望闻问切，上来先看看舌苔，发现舌苔有异常，先让患者做简单的检查，
比如抽血，根据抽血的结果，如果能判断问题，就开药，否则，
就让患者做进一步的检查，比如CT，最后根据所有信息去确诊。
他不会一条路走到黑，而是在过程中动态调整。
```

**改写要点**：
- ✅ 完整场景（起点：看舌苔 → 过程：抽血/CT → 终点：确诊）
- ✅ 生活化比喻（老中医看病）
- ✅ 删除技术流程（调日志→监控→SQL）
- ✅ 拆分段落（传统模式一段，交错思维一段）

---

### 示例4：口语化过渡 + 悬念引导

**原文（特征3+10）**：
```
此外，扩展思考还支持一个强大功能：交错思维（interleaved thinking）。
（然后直接讲完所有内容）
```

**改写后（原则3+10）**：
```
你可能要问了，DeepSeek R1不是也可以做到麽？
Claude的扩展思考跟DeepSeek有什么区别？

这个问题问到核心了，本质的问题是**交错思维（Interleaved Thinking）**。

我们后文会详细介绍。
```

**改写要点**：
- ✅ 用疑问句过渡（你可能要问了）
- ✅ 设置悬念（后文详述）
- ✅ 口语化表达（问到核心了）

---

### 示例5：单点段落 + 精简细节

**原文（特征4+9）**：
```
扩展思考不是免费午餐。平均延迟156秒，也就是说你问一个问题，要等将近2分半。
更要命的是成本——thinking过程会生成大量tokens（通常是正常输出的3-5倍），
一次64K的深度推理就要花掉约$0.96，一天调用100次就烧掉$96。

所以，关键是用对地方。适合"一旦选错成本巨大"的决策——架构设计、复杂调试、
算法优化，这些值得花2分钟等一个深思熟虑的方案。反过来，简单代码生成、
文档翻译、格式转换，用标准模式就够了，让Claude深度思考"怎么写一个Hello World"纯属浪费。
```

**改写后（原则4+9）**：
```
当然，有一利就有一弊，扩展思考的问题也很突出：又贵又慢。
一个问题平均延迟两分半钟，而且还消耗大量tokens。

所以拓展思考好不好，关键是用对地方。
类似软件架构设计这种对结果要求极高的决策，多花时间跟钱是可以接受的。

反过来，如果是写写简单的代码、文档翻译等，用标准模式就够了，
让Claude深度思考"怎么写一个Hello World"纯属浪费。
```

**改写要点**：
- ✅ 拆分为3个独立段落
- ✅ 删除具体数字（156秒、$0.96、3-5倍）
- ✅ 保留核心观点（贵、慢、用对地方）

---

## 🔄 持续优化

### 如何补充示例

每次改写文章后，如果发现新的AI特征或有效的改写方法：

1. **补充到AI特征库**：
   ```markdown
   ### 【特征X】新发现的特征名
   **症状表现**：
   - 具体表现1
   - 具体表现2

   **典型案例**：
   ❌ 原文示例
   ```

2. **补充到改写原则**：
   ```markdown
   ### 【原则X】对应的改写方法
   **针对特征**：【特征X】

   **改写方法**：
   - 具体做法

   **执行步骤**：
   1. 步骤1
   2. 步骤2
   ```

3. **补充到示例库**：
   ```markdown
   ### 示例X：原则组合名称

   **原文（特征X+Y）**：
   ❌ 原文

   **改写后（原则X+Y）**：
   ✅ 改写后

   **改写要点**：
   - ✅ 要点1
   - ✅ 要点2
   ```

### 质量验证

- **朱雀检测**：目标AI浓度 < 30%
- **人工阅读**：非技术背景的人能否听懂

---

## 📝 版本记录

- **v1.0** (2025-10-04)：首次创建，基于Claude扩展思考文章改写经验
  - 10个AI特征
  - 10条改写原则
  - 5个典型示例
